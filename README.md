
# Projeto: Leitura de Libras com VisÃ£o Computacional

Este projeto utiliza **Python**, **OpenCV**, **MediaPipe** e **scikit-learn** para reconhecer sinais da LÃ­ngua Brasileira de Sinais (LIBRAS) capturados pela webcam. AlÃ©m do reconhecimento em tempo real, o sistema inclui um **modo de jogo simples** onde o usuÃ¡rio tenta acertar letras exibidas na tela com os sinais corretos.

## ğŸ“ Estrutura do Projeto

```
ğŸ“¦ Projeto/
â”œâ”€â”€ dados/                    # ContÃ©m arquivos CSV com dados coletados
â”œâ”€â”€ coleta_dados.py          # Script para capturar dados de um gesto especÃ­fico
â”œâ”€â”€ juntar_dados.py          # Une todos os arquivos CSV em um sÃ³ para treinamento
â”œâ”€â”€ treino_modelo.py         # Treina o modelo de machine learning
â”œâ”€â”€ reconhecimento_tempo_real.py # Executa o reconhecimento em tempo real com webcam
â”œâ”€â”€ modelo_libras.pkl        # Arquivo gerado com o modelo treinado
â”œâ”€â”€ label_encoder.pkl        # Arquivo com os rÃ³tulos codificados
â””â”€â”€ README.md                # DocumentaÃ§Ã£o do projeto
```

## ğŸ§  Tecnologias Utilizadas

- Python 3.10+
- OpenCV
- MediaPipe
- Scikit-learn
- Pandas
- NumPy

## ğŸ§ª InstalaÃ§Ã£o das DependÃªncias

VocÃª pode instalar todas as bibliotecas necessÃ¡rias com o seguinte comando:

```bash
pip install pandas numpy opencv-python mediapipe scikit-learn
```

## ğŸš€ Como Executar o Projeto

### ğŸ® Modo de Jogo (jogo_libras.py)

- Exibe uma **letra-alvo** que o usuÃ¡rio deve representar com as mÃ£os.
- Uma **caixa verde** na tela indica onde fazer o gesto.
- Se o gesto for reconhecido corretamente:
  - A pontuaÃ§Ã£o Ã© incrementada.
  - Uma confirmaÃ§Ã£o **visual no canto superior direito** aparece com a mensagem "Acertou!" em verde.
  - Uma nova letra-alvo Ã© gerada.

### â–¶ï¸ Como executar

1. Certifique-se de que o arquivo `modelo_libras.pkl` (modelo treinado) esteja no mesmo diretÃ³rio.
2. Execute o modo jogo com:

```bash
python jogo_libras.py
```

3. Pressione **Q** para sair.

---
## ğŸ’ª Treinando o modelo

### 1. Coleta de Dados
Execute o script abaixo e pressione:
- `c` para iniciar a coleta.
- `q` para sair.

```bash
python coleta_dados.py
```

Os dados serÃ£o salvos no diretÃ³rio `dados/`.

### 2. Juntar os Dados
ApÃ³s coletar vÃ¡rias letras (como `dados_letra_A.csv`, `dados_letra_B.csv`, etc.), execute:

```bash
python juntar_dados.py
```

Isso criarÃ¡ um arquivo Ãºnico chamado `dados_treinamento.csv`.

### 3. Treinar o Modelo
Para treinar o classificador com KNN:

```bash
python treino_modelo.py
```

Esse processo gerarÃ¡ os arquivos `modelo_libras.pkl` e `label_encoder.pkl`.

### 4. Reconhecimento em Tempo Real

```bash
python reconhecimento_tempo_real.py
```

Uma caixa verde serÃ¡ exibida na tela indicando a Ã¡rea onde o gesto deve ser feito. O modelo tentarÃ¡ reconhecer a letra correspondente ao gesto da mÃ£o em tempo real.

## âœ… Status

âœ… Modo de jogo  
âœ… Coleta de dados  
âœ… Treinamento de modelo  
âœ… Reconhecimento em tempo real  

## ğŸ“Œ ObservaÃ§Ãµes

- Certifique-se de que a mÃ£o esteja bem visÃ­vel na Ã¡rea indicada da webcam.
- O projeto reconhece apenas as letras que foram treinadas.


